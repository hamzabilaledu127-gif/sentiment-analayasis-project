{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "413085d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "302/302 - 19s - 62ms/step - accuracy: 0.4482 - loss: 0.9702 - val_accuracy: 0.4120 - val_loss: 0.9917\n",
      "Epoch 2/10\n",
      "302/302 - 22s - 73ms/step - accuracy: 0.4417 - loss: 1.0199 - val_accuracy: 0.4975 - val_loss: 0.9707\n",
      "Epoch 3/10\n",
      "302/302 - 20s - 65ms/step - accuracy: 0.4457 - loss: 0.9760 - val_accuracy: 0.4378 - val_loss: 0.9704\n",
      "Epoch 4/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4453 - loss: 0.9667 - val_accuracy: 0.4892 - val_loss: 0.9605\n",
      "Epoch 5/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4473 - loss: 0.9555 - val_accuracy: 0.4357 - val_loss: 0.9698\n",
      "Epoch 6/10\n",
      "302/302 - 14s - 45ms/step - accuracy: 0.4632 - loss: 0.9500 - val_accuracy: 0.5573 - val_loss: 0.9632\n",
      "Epoch 7/10\n",
      "302/302 - 15s - 48ms/step - accuracy: 0.4556 - loss: 0.9492 - val_accuracy: 0.3842 - val_loss: 0.9717\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "Results for fold 1\n",
      "Accuracy: 0.4772\n",
      "Precision: 0.6497\n",
      "Recall: 0.3473\n",
      "F1-Score: 0.3310\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 17s - 58ms/step - accuracy: 0.4551 - loss: 0.9586 - val_accuracy: 0.3149 - val_loss: 0.9788\n",
      "Epoch 2/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4544 - loss: 0.9496 - val_accuracy: 0.5784 - val_loss: 0.9589\n",
      "Epoch 3/10\n",
      "302/302 - 15s - 49ms/step - accuracy: 0.4577 - loss: 0.9492 - val_accuracy: 0.3581 - val_loss: 0.9769\n",
      "Epoch 4/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4547 - loss: 0.9600 - val_accuracy: 0.5631 - val_loss: 0.9589\n",
      "Epoch 5/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4539 - loss: 0.9520 - val_accuracy: 0.4062 - val_loss: 0.9648\n",
      "Epoch 6/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4601 - loss: 0.9443 - val_accuracy: 0.4672 - val_loss: 0.9595\n",
      "Epoch 7/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4536 - loss: 0.9448 - val_accuracy: 0.5108 - val_loss: 0.9594\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Results for fold 2\n",
      "Accuracy: 0.5220\n",
      "Precision: 0.6643\n",
      "Recall: 0.3411\n",
      "F1-Score: 0.2672\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 19s - 63ms/step - accuracy: 0.4582 - loss: 0.9567 - val_accuracy: 0.3112 - val_loss: 0.9754\n",
      "Epoch 2/10\n",
      "302/302 - 14s - 46ms/step - accuracy: 0.4616 - loss: 0.9495 - val_accuracy: 0.4888 - val_loss: 0.9668\n",
      "Epoch 3/10\n",
      "302/302 - 15s - 49ms/step - accuracy: 0.4535 - loss: 0.9437 - val_accuracy: 0.5759 - val_loss: 0.9599\n",
      "Epoch 4/10\n",
      "302/302 - 20s - 65ms/step - accuracy: 0.4589 - loss: 0.9460 - val_accuracy: 0.4954 - val_loss: 0.9767\n",
      "Epoch 5/10\n",
      "302/302 - 21s - 70ms/step - accuracy: 0.4589 - loss: 0.9779 - val_accuracy: 0.5589 - val_loss: 0.9552\n",
      "Epoch 6/10\n",
      "302/302 - 14s - 46ms/step - accuracy: 0.4500 - loss: 0.9512 - val_accuracy: 0.5477 - val_loss: 0.9579\n",
      "Epoch 7/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4526 - loss: 0.9499 - val_accuracy: 0.4207 - val_loss: 0.9778\n",
      "Epoch 8/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4550 - loss: 0.9436 - val_accuracy: 0.4664 - val_loss: 0.9698\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "Results for fold 3\n",
      "Accuracy: 0.4981\n",
      "Precision: 0.6787\n",
      "Recall: 0.3482\n",
      "F1-Score: 0.2812\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 18s - 60ms/step - accuracy: 0.4555 - loss: 0.9543 - val_accuracy: 0.3108 - val_loss: 0.9731\n",
      "Epoch 2/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4541 - loss: 0.9493 - val_accuracy: 0.3112 - val_loss: 0.9787\n",
      "Epoch 3/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4563 - loss: 0.9391 - val_accuracy: 0.3108 - val_loss: 0.9779\n",
      "Epoch 4/10\n",
      "302/302 - 15s - 51ms/step - accuracy: 0.4552 - loss: 0.9386 - val_accuracy: 0.5726 - val_loss: 0.9733\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Results for fold 4\n",
      "Accuracy: 0.4033\n",
      "Precision: 0.4686\n",
      "Recall: 0.3285\n",
      "F1-Score: 0.5249\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 18s - 59ms/step - accuracy: 0.4524 - loss: 0.9893 - val_accuracy: 0.4577 - val_loss: 0.9917\n",
      "Epoch 2/10\n",
      "302/302 - 14s - 45ms/step - accuracy: 0.4574 - loss: 0.9739 - val_accuracy: 0.4921 - val_loss: 0.9773\n",
      "Epoch 3/10\n",
      "302/302 - 22s - 72ms/step - accuracy: 0.4574 - loss: 0.9630 - val_accuracy: 0.5730 - val_loss: 0.9634\n",
      "Epoch 4/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4504 - loss: 0.9519 - val_accuracy: 0.4884 - val_loss: 0.9667\n",
      "Epoch 5/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4601 - loss: 0.9473 - val_accuracy: 0.5598 - val_loss: 0.9676\n",
      "Epoch 6/10\n",
      "302/302 - 14s - 46ms/step - accuracy: 0.4570 - loss: 0.9435 - val_accuracy: 0.5730 - val_loss: 0.9581\n",
      "Epoch 7/10\n",
      "302/302 - 15s - 48ms/step - accuracy: 0.4572 - loss: 0.9407 - val_accuracy: 0.3112 - val_loss: 0.9877\n",
      "Epoch 8/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4576 - loss: 0.9392 - val_accuracy: 0.5730 - val_loss: 0.9735\n",
      "Epoch 9/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4545 - loss: 0.9376 - val_accuracy: 0.5730 - val_loss: 0.9705\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Results for fold 5\n",
      "Accuracy: 0.4705\n",
      "Precision: 0.8235\n",
      "Recall: 0.3333\n",
      "F1-Score: 0.2133\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 19s - 62ms/step - accuracy: 0.4501 - loss: 0.9626 - val_accuracy: 0.5390 - val_loss: 0.9624\n",
      "Epoch 2/10\n",
      "302/302 - 14s - 46ms/step - accuracy: 0.4465 - loss: 0.9545 - val_accuracy: 0.5710 - val_loss: 0.9669\n",
      "Epoch 3/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4632 - loss: 0.9445 - val_accuracy: 0.5755 - val_loss: 0.9689\n",
      "Epoch 4/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4503 - loss: 0.9445 - val_accuracy: 0.5755 - val_loss: 0.9659\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Results for fold 6\n",
      "Accuracy: 0.4832\n",
      "Precision: 0.6498\n",
      "Recall: 0.3370\n",
      "F1-Score: 0.2806\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 18s - 59ms/step - accuracy: 0.4503 - loss: 0.9541 - val_accuracy: 0.5768 - val_loss: 0.9563\n",
      "Epoch 2/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4516 - loss: 1.0027 - val_accuracy: 0.5768 - val_loss: 0.9430\n",
      "Epoch 3/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4444 - loss: 0.9682 - val_accuracy: 0.5768 - val_loss: 0.9536\n",
      "Epoch 4/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4594 - loss: 0.9455 - val_accuracy: 0.5768 - val_loss: 0.9533\n",
      "Epoch 5/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4494 - loss: 0.9437 - val_accuracy: 0.5768 - val_loss: 0.9693\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Results for fold 7\n",
      "Accuracy: 0.4869\n",
      "Precision: 0.8290\n",
      "Recall: 0.3333\n",
      "F1-Score: 0.2183\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 18s - 60ms/step - accuracy: 0.4607 - loss: 0.9587 - val_accuracy: 0.5822 - val_loss: 0.9590\n",
      "Epoch 2/10\n",
      "302/302 - 14s - 47ms/step - accuracy: 0.4464 - loss: 0.9494 - val_accuracy: 0.4581 - val_loss: 0.9557\n",
      "Epoch 3/10\n",
      "302/302 - 16s - 54ms/step - accuracy: 0.4517 - loss: 1.0025 - val_accuracy: 0.5037 - val_loss: 0.9635\n",
      "Epoch 4/10\n",
      "302/302 - 17s - 55ms/step - accuracy: 0.4570 - loss: 0.9731 - val_accuracy: 0.4548 - val_loss: 0.9596\n",
      "Epoch 5/10\n",
      "302/302 - 16s - 54ms/step - accuracy: 0.4498 - loss: 0.9554 - val_accuracy: 0.4506 - val_loss: 0.9553\n",
      "Epoch 6/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4501 - loss: 0.9462 - val_accuracy: 0.5822 - val_loss: 0.9474\n",
      "Epoch 7/10\n",
      "302/302 - 16s - 52ms/step - accuracy: 0.4477 - loss: 0.9458 - val_accuracy: 0.4552 - val_loss: 0.9484\n",
      "Epoch 8/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4537 - loss: 0.9439 - val_accuracy: 0.4398 - val_loss: 0.9614\n",
      "Epoch 9/10\n",
      "302/302 - 20s - 67ms/step - accuracy: 0.4572 - loss: 0.9420 - val_accuracy: 0.4411 - val_loss: 0.9580\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Results for fold 8\n",
      "Accuracy: 0.4548\n",
      "Precision: 0.8183\n",
      "Recall: 0.3333\n",
      "F1-Score: 0.2084\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 19s - 62ms/step - accuracy: 0.4537 - loss: 0.9566 - val_accuracy: 0.5755 - val_loss: 0.9588\n",
      "Epoch 2/10\n",
      "302/302 - 15s - 49ms/step - accuracy: 0.4523 - loss: 0.9476 - val_accuracy: 0.5768 - val_loss: 0.9652\n",
      "Epoch 3/10\n",
      "302/302 - 14s - 48ms/step - accuracy: 0.4469 - loss: 0.9875 - val_accuracy: 0.4884 - val_loss: 0.9772\n",
      "Epoch 4/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4443 - loss: 0.9779 - val_accuracy: 0.4672 - val_loss: 0.9703\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "Results for fold 9\n",
      "Accuracy: 0.4922\n",
      "Precision: 0.8307\n",
      "Recall: 0.3333\n",
      "F1-Score: 0.2199\n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "302/302 - 19s - 63ms/step - accuracy: 0.4524 - loss: 0.9680 - val_accuracy: 0.5774 - val_loss: 0.9757\n",
      "Epoch 2/10\n",
      "302/302 - 15s - 50ms/step - accuracy: 0.4585 - loss: 0.9455 - val_accuracy: 0.5392 - val_loss: 0.9535\n",
      "Epoch 3/10\n",
      "302/302 - 15s - 49ms/step - accuracy: 0.4296 - loss: 1.0236 - val_accuracy: 0.4322 - val_loss: 0.9788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "302/302 - 21s - 68ms/step - accuracy: 0.4576 - loss: 0.9651 - val_accuracy: 0.3820 - val_loss: 0.9783\n",
      "Epoch 5/10\n",
      "302/302 - 14s - 46ms/step - accuracy: 0.4552 - loss: 0.9498 - val_accuracy: 0.5168 - val_loss: 0.9685\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "Results for fold 10\n",
      "Accuracy: 0.4746\n",
      "Precision: 0.6560\n",
      "Recall: 0.3454\n",
      "F1-Score: 0.2883\n",
      "\n",
      "\n",
      "Average results after 10-fold cross-validation:\n",
      "Accuracy: 0.4763\n",
      "Precision: 0.7069\n",
      "Recall: 0.3381\n",
      "F1-Score: 0.2833\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "filename = 'all_facebook_and_twitter_dataset.xlsx'\n",
    "df = pd.read_excel(filename)\n",
    "\n",
    "# Step 2: Preprocess the dataset\n",
    "comments = df['Comments'].astype(str)  # Convert comments to string type\n",
    "labels = df['M-Class']\n",
    "\n",
    "# Convert labels to integer using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Tokenize the comments and convert them to integer sequences\n",
    "vocab_size = 10000\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(comments)\n",
    "comments_seq = tokenizer.texts_to_sequences(comments)\n",
    "\n",
    "# Set maximum sequence length\n",
    "max_length = max(len(seq) for seq in comments_seq)\n",
    "\n",
    "# Pad the sequences to a consistent length\n",
    "comments_padded = pad_sequences(comments_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Define the function to create the model\n",
    "def create_model():\n",
    "    embedding_dim = 100\n",
    "    rnn_units = 64\n",
    "    dropout_rate = 0.5\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim),\n",
    "        SimpleRNN(rnn_units, return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the function to train and evaluate the model using k-fold cross-validation\n",
    "def k_fold_cross_validation(k):\n",
    "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "    results = {'accuracy': [], 'precision': [], 'recall': [], 'f1_score': []}\n",
    "\n",
    "    for train_index, test_index in kfold.split(comments_padded):\n",
    "        X_train, X_test = comments_padded[train_index], comments_padded[test_index]\n",
    "        y_train, y_test = labels_encoded[train_index], labels_encoded[test_index]\n",
    "\n",
    "        model = create_model()\n",
    "\n",
    "        batch_size = 32\n",
    "        epochs = 10\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks=[early_stopping], verbose=2)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred_probs = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "        # Calculate classification report\n",
    "        report = classification_report(y_test, y_pred_classes, target_names=label_encoder.classes_, output_dict=True, zero_division=1)\n",
    "\n",
    "        # Extract individual metrics\n",
    "        results['accuracy'].append(report['accuracy'])\n",
    "        results['precision'].append(report['macro avg']['precision'])\n",
    "        results['recall'].append(report['macro avg']['recall'])\n",
    "        results['f1_score'].append(report['macro avg']['f1-score'])\n",
    "\n",
    "        print(f\"Results for fold {fold_no}\")\n",
    "        print(f\"Accuracy: {report['accuracy']:.4f}\")\n",
    "        print(f\"Precision: {report['macro avg']['precision']:.4f}\")\n",
    "        print(f\"Recall: {report['macro avg']['recall']:.4f}\")\n",
    "        print(f\"F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
    "        print(\"\\n\")\n",
    "        fold_no += 1\n",
    "\n",
    "    # Average the results\n",
    "    avg_results = {metric: np.mean(scores) for metric, scores in results.items()}\n",
    "    return avg_results\n",
    "\n",
    "# Number of folds for k-fold cross-validation\n",
    "k = 10\n",
    "\n",
    "# Evaluate the model using k-fold cross-validation\n",
    "avg_results = k_fold_cross_validation(k)\n",
    "\n",
    "print(f\"Average results after {k}-fold cross-validation:\")\n",
    "print(f\"Accuracy: {avg_results['accuracy']:.4f}\")\n",
    "print(f\"Precision: {avg_results['precision']:.4f}\")\n",
    "print(f\"Recall: {avg_results['recall']:.4f}\")\n",
    "print(f\"F1-Score: {avg_results['f1_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0782266d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
